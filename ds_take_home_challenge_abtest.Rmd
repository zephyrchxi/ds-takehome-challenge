---
title: "ds-takehome-challenge-abtest"
author: "Chelsey"
date: "8/11/2020"
output: html_document
---
```{r}
#libraries needed

library(dplyr)
library(ggplot2)
library(rpart)
```

```{r}

#set working directory
setwd("D:/Projects")
working_dir <- getwd()

#create a directroy for your saved graph
data_dir <- file.path(working_dir, "data_ds_takehome_abtest")
dir.create(data_dir)

#load data
test <- read.csv(file.path("data_ds_takehome_abtest", "test_table.csv"))
user <- read.csv(file.path("data_ds_takehome_abtest", "user_table.csv"))

```

```{r}

# merge to one dataset

data <- merge(test, user, by = "user_id", all.x = TRUE)

data$source <- as.factor(data$source)
data$device <- as.factor(data$device)
data$browser_language <- as.factor(data$browser_language)
data$ads_channel <- as.factor(data$ads_channel)
data$browser <- as.factor(data$browser)
data$country <- as.factor(data$country)
data$sex <- as.factor(data$sex)

summary(data)

```

Check test results - Spain conversion rate is much better than the rest of LatAm countries

```{r}

data_conversion_country <- 
  data %>% 
  filter(test == 0 )%>%
  group_by(country) %>% 
  summarise(conversion_rate = mean(conversion)) %>%
  arrange(desc(conversion_rate)) %>%
  na.omit()

head(data_conversion_country)

ggplot(data_conversion_country,
       aes(x = reorder(country,-conversion_rate), y = conversion_rate)) +
  geom_col() 



```
The conversion rate for Spain is as high as 8.0%, followed by El Salvador as the second highest at 5.4%. Thus it's true that Spain converts much better than the other countries.

## A/B Test
```{r}
# investigate a/b test result
data_test <- data %>%
  filter(test == 1)

data_control <- data %>%
  filter(test == 0)

test_conversion <- mean(data_test$conversion)
control_conversion <- mean(data_control$conversion)

test_conversion
control_conversion

# we can also do a t-test

t.test(data$conversion[data$test == 1], data$conversion[data$test == 0])

```

Users are converted at 4.3% in the test, which users not in the test are converted at a rate of 5.5%, the conversion of test sample is smaller than the control sample. If the test result is negative, the difference should be dramatic. The reason for weird A/B test results are:

1. We didn't collect enough data
2. Some bias has been introduced in the experiment so that test/control users are not really random.

1) test for the assumption 1

```{r}
# plot day by day

data_test_by_day <-  
  data %>%
  group_by(date) %>%
  summarize(test_vs_control = mean(conversion[test == 1])/mean(conversion[test ==0]))

qplot(date, test_vs_control, data= data_test_by_day, geom = "line", group = 1)

```

From the plot, we notice a couple of things:
1. Test has constantly been worse than control and there is relatively little variance across days.That probably means that we do not have enough data, but there were bias in the experiment setup.
2. We only ran for 5 days, we should always run the test for at leat 2 full weeks to capture weekly pattern and avoid seasonality influence.


2) test for assumption 2

Ideally, the distribution of people in test and control for each segment should be the same. 

```{r}
# visualize different source

data$test <- as.factor(data$test)

ggplot(data, aes(x = source)) +
   geom_bar(aes(fill = test), position = "dodge") 

ggplot(data, aes(x = device)) +
   geom_bar(aes(fill = test), position = "dodge") 

ggplot(data, aes(x = browser_language)) +
   geom_bar(aes(fill = test), position = "dodge") 

ggplot(data, aes(x = browser)) +
   geom_bar(aes(fill = test), position = "dodge") 

ggplot(data, aes(x = sex)) +
   geom_bar(aes(fill = test), position = "dodge") 

ggplot(data, aes(x = sex)) +
   geom_bar(aes(fill = test), position = "dodge") 

ggplot(data, aes(x = country)) +
   geom_bar(aes(fill = test), position = "dodge") 


data_by_country  <- 
  data %>%
  count(country, test) %>%
  group_by(country) %>%
  summarise(test_control_ratio = n[test == 1]/n[test == 0]) %>%
  arrange(desc(test_control_ratio))

data_by_country
```

Uruguay, Argentina for example has vastly different number of observations for test and control. This is the reason to do a t-test individually for each country. 


```{r}

data_test_1 = subset(data, country != "Spain") 


data_test_country  <- 
  data_test_1 %>%
  group_by(country) %>%
  summarise(p_value = t.test(conversion[test==1],conversion[test==0])$p.value,
            conversion_test = t.test( conversion[test==1],
                                      conversion[test==0])$estimate[1],
            conversion_control = t.test( conversion[test==1],
                                         conversion[test==0])$estimate[2],
             Validity = p_value < 0.05) %>%
 arrange (p_value)

data_test_country


# detach(package:plyr) if group_by doesn't work


````
the t test result clearly appears non significant between localized and non-localized translation on the website. The final column - Validaity provides FALSE when test is not significant with a significane value of 0.05.

Since we accept null hypothesis, we can assume that the conversion rate hasn't increased either. 

## Recommendation

1) Run the experiement for longer, ideally more than 14 days to ensure weekly pattern and avoid seasonality effect.
2) Avoid bias when assigning test users.
